\section{The Development Process}
%Meta shit%
Our 6\textsuperscript{th} semester was a multi--group project collaboration heavily focused on the development process.
This focus gave us a clear idea of how we wanted the development process to be shaped for this semester project.
Ideally we wanted to reduce the overhead from Scrum and go back to using only a few elements from Scrum, while maintaining some of the additional processes such as code--review.
Firstly we describe our initial plan for the development process and subsequently describe how we ended up using the tools in reality.
%%%%%%%%%%%
\subsection{Planned Development Process}
%Meta Shit%
Prior to starting development on the project we first established which tools and methods we wanted to utilise for our development process.
This subsection covers our reasons for choosing those tools and methods.
%%%%%%%%%%%
\subsubsection{Scrum}
As mentioned our 6\textsuperscript{th} semester was heavily focused on the development process, part of this was using Scrum correctly with planned sprints and a lot of cross group meetings.
For this, our 7\textsuperscript{th}, semester we decided that using Scrum with sprints and sprint meetings would be too much overhead, as we simply wanted to utilise some of the management tools we had successfully used in the past.
These tools are Daily Scrum and a Scrum Board.
The Daily Scrum is a short meeting in the beginning of the day where each member answers three questions:
\begin{itemize}
    \item \textit{What have you done since the last meeting?}
    \item \textit{What do you intent to do today?}
    \item \textit{Is there anything stopping you?}
\end{itemize}
These three questions allow for a quick overview of what others are doing and also provides an opportunity each day to ask for help if there are any uncertainties about a task.
We wanted to use Daily Scrum in order to synchronise the team, i.e. share information such that everyone knows what is going on.
The Scrum Board allows for an overview of the project as a whole.
The Scrum Board contains user stories and tasks that divide the development process into smaller more manageable workloads.
%Step down
%hard scrum to a few elements
%Board+Daily
\subsubsection{Phabricator \& Code--Review}
In order to implement some quality control we decided to use a tool called Phabricator\footnote{\url{https://www.phacility.com/phabricator/}}, which is a software development tool.
Phabricator facilitates an environment designed for code--review which is another method we wanted to use.
Phabricator also works with Git\footnote{\url{https://git-scm.com/}}, which is our version control system of choice, as such it works with our version control.
Using Git we also used naming conventions for our branches as to identify them, we have three types of branches, \textbf{release}, \textbf{development} and \textbf{bugfix}.
At all times a working \textbf{release} branch must exist, the branch should be buildable to all times.
A \textbf{development} branch is for new features and a \textbf{bugfix} branch is for fixing bugs.
Whenever something is completed in a \textbf{development} or \textbf{bugfix} branch, and should be pushed to the \textbf{release} branch, it goes through a review process.

The review process helps reduce the amount of iterations a task would go through, i.e. number of \textbf{bugfix} branches we would create.
The review process consists of a linter, unit tests, and reviews by other group members.
We decided that the review process should require at least two reviewers.
This was also intended to help with knowledge sharing even further than the Daily Scrum, as anything pushed to the \textbf{release} branch would have involved at least three group members.
We had used a similar process on the 6\textsuperscript{th} semester, however review had been strict and rigid which meant it could take over a week to get anything through the review phase.
The code written during our 6\textsuperscript{th} semester would become a codebase for new students at a later point, which is why we chose to be so strict and rigid with out review.
As we did not want to spend too much time on review, we agreed that reviews should be less rigid and focus on design issues, rather than naming conventions and issues without any real effect since the code would not be inherited.
%Unit tests and Linter // Version Control Biatch git/arc
%Code--review // 2 reviewers min.
\subsubsection{Test Focus}
%may require some input from our testers
As \cref{sec:testing} describes we believe that testing is important, particularly in order to demonstrate that a system not only works, but works as intended.
In order to achieve a sufficient level of testing to prove the server works as intended, we decided that integration and system tests were the way to do so for the server.
Another criteria for the server is several scalability measures, while most of the scalability measures established in \cref{sec:scalability} can not be systematically tested, load scalability can.
This led us to require load testing, system tests and integration tests.
%Systematic Integration tests(JUnit) not interesting if no interaction with DB, thus Integration > Unit
%Load testing, system test(testing all services) JMeter
\subsubsection{Jenkins/CI}\fxnote{This needs writing}
%May not be written
%Finds errors that may not occur on a single computer but would not occur on others.
%Working version, always
\subsection{The Development Process in Reality}
%Meta Shit%
While we had a plan for how we wanted to develop, it did not quite turn out the way we wanted it to.
Our plan to use elements of Scrum was the point we deviated from the most.
The scheduling of our time this semester is what caused us to deviate from our plans, in particular for Scrum.
The scheduling issues were caused by the amount of time spend on courses this year, in particular on mini-projects which all the courses had.
Since the group members had different courses this semester, only about one day a week the entirety of the group would be together in the group room.
This issues is expanded upon in \cref{sub:time_scheduling}.
%%%%%%%%%%%
\subsubsection{Scrum}
Despite wanting to use the Daily Scrum and Scrum Board tools, the Daily Scrum ended up being more of a weekly thing.
While the Daily Scrum suffered, the Scrum Board prevailed and gave us the benefit of seeing what tasks were currently being worked on, and what tasks had yet to be started.
The scheduling issues made us realise we needed to work weekends in order to make up for the less scheduled time.
Working weekends made Monday the ideal day to do our weekly Scrum; despite Monday being assigned to mini-project work for most of the group.
In the later months of the project the courses started to fade out and the mini-projects were ending, this meant we had more time in the group room to work which in turn allowed us to revive our Daily Scrum meetings.
%Scrum? Not. Daily scrum, 2 times a week at best. Scheduling issues, 1.5 - 2 days a week for majority, Hours available graph?
%Realizing we need to work weekends4graph.
\subsubsection{Phabricator \& Code--Review}
Unlike our Scrum tools, the use of Phabricator and code--reviews went well, although a few changes were made to code--review.
Originally not wanting reviews to take too long as we were expecting to iterate upon things, we ended up doing rigid code--reviews anyway.
Doing several iterations, while effective is also blocking, since you can not iterate on something until it has been done the first time.
With the majority of our time being stacked in the end of the semester and we have six group members, waiting on iterations would be blocking.
As such ensuring high quality through a rigid review structure meant less iterations and in turn a workload better suited for parallel development.
%Changins course to a more rigid review structure
%Phab workflow, Review process
%Test focused development, review+test relly handy with exponential workload as several iterations would block too much
\subsubsection{Test Focus}\fxnote{This is very short, not quite sure what else to write, also i don't know about the name for this, suggestions?}
%May require some input - Eftersom vi har et dedicated test afsnit ved jeg ikke helt hvad man skulle skrive her, vi har jo rimelig successfully gjort det som vi ville mht. test
As documented in \cref{sec:testing} we managed to successfully thoroughly test the system in various ways, integration testing with JUnit and Hamcrest, load testing with Apache JMeter and system tests also trough Apache JMeter.
%Systematic Integration tests(JUnit) not interesting if no interaction with DB, thus Integration > Unit
%Load testing, system test(testing all services) JMeter
\subsubsection{Jenkins/CI}\fxnote{this needs writing}
%May not be written
\section{Process Reflection}
%Meta Shit%
With the differences between our development plan and the actual execution described we consider the success, or lack thereof, of our development method and possible improvements which could have yielded a better result.
This section evaluates each of the core values that we have based our development around:
\begin{itemize}
    \item Code--Review.
    \item Testing.
    \item Continuous integration.
    \item Choosing to focus on the server, make a proof of concept consumer client and emulate the producer client.
\end{itemize}
Before expanding on those core development ideas we will take a look at the time scheduling issues, as this has affected our development, the Scrum tools most of all.
%%%%%%%%%%%
\subsection{Time Scheduling}\label{sub:time_scheduling}
%Might just scrap this if it ends up just sounding as an excuse
As previously mentioned each course this semester had a mini-project, the result of this was that each group member only had about one and a half day a week scheduled for this project, with only one day shared amongst the group members.
This timetable made it particularly hard for the group to start the project as we had to figure out what we wanted to do, which direction to take the project and how to do it which required the entirety of the group gathered for discussions.
This cost us a lot of time early on, and as such we decided that we should work weekends, however as mentioned this did not help our Daily Scrum which ended up being neglected in the early months.

This is the area in which our development method failed the most, we did not consider our timetable when planning how we wanted to develop, instead we simply went with what we knew.
The issues this caused were handled, but the proper solution would have been to plan around this as we did have our course schedule available.

%Would have had a less of an effect if our project used parts of miniprojects.
%Compressed time frame, 1.5 months instead of 4.
\subsection{Code--Review}
Our systematic code--review has been a supremely effective tool, even more so due to the timetable issues as it helped rectify them.
Code--review helped us ensure that anything produced is of such a quality that large scale refactoring rarely happened once it has passed through review.
The higher quality gained from code--review in turn meant less iterations were required, which helped rectify our timetable issues as iterations are blocked by one another.

Code--review also helped make up for our failed Daily Scrum in that it acted as tool for knowledge sharing.
Originally this was supposed to be an effect we had through Daily Scrum, but as we failed to utilise that tool, code--review picked up the slack in this area by requiring at least two reviewers.
By requiring at least two reviewers we guaranteed that half the group have been involved in every part of the system.

\bigskip
Despite the positives of code--review, it does have its negatives.
Code--review takes time, in some cases too much, this means that if other parts of the system are dependent on a part currently being reviewed, they will be blocked until it passes review.
This downside can be somewhat helped by prioritising reviews of blocking parts.
Another downside of code--review is how time--consuming it is.
While code--review helps to ensure a certain quality it also means that if something has to be redone after already having passed review, an even greater amount of time is lost, as the entire thing will have to be redone and re--reviewed.

Overall few things had to be iterated upon once through review, as such we deem that overall our code--review has been successfully executed and effective.
Through knowledge sharing and reducing number of iterations required it has also helped diminish the negative effect of our time scheduling problems.
%Code-review perks, hard to get stuff through but for the most part we barely have to go back once it's in master.
\subsection{Test Focus}
%Systematic Integration tests(JUnit) not interesting if no interaction with DB, thus Integration > Unit
%Load testing, system test(testing all services) JMeter
Testing the system has been a high priority for us throughout this project, as such one would expect that it has also yielded some value.
Writing tests requires a different train of thought than writing the functionality, as a result not only may the test find errors, but the action of writing the test may also help identify errors.
While we have not been tracking how many errors we have found through the different test measures, we would estimate that about one in every three integration test has helped us identify an error.
By using a systematic test framework such as JUnit, each test written becomes a regression test.
While the fact that tests yield errors when written is useful, the most useful part of our test setup is the regression tests.
Regression testing ensures that the system works as intended when other components are added or changed.
Regression tests also ties in closely with our continuous integration setup which runs all tests whenever something is pushed to the \textbf{release} branch.

\bigskip
Testing that the functionality within the system works is important, but it also has to work for the clients using the system.
In order to test that the system works for clients we used system testing as described in \cref{sec:testing}.
The system tests, test that the API acts as the user expects it to, which would be as the API specification describes it, as the Enunciate documentation at refhere\fxnote{Insert ref to enunciate documentation!} describes.
In order to find as many errors as possible we also used smoke testing for the API which helped find some errors that the system tests did not.\fxnote{Eksempel?(Truls/Sass)}
With scalability being of importance to our project we decided to test this as well through load testing, the load test helped us identify bottlenecks in the server, which we in turn could act upon.\fxnote{Troels/Jesper add example for system test yield, evt. om SQL Query rewrite coz bottleneck}

While testing is a time consuming endeavor, the time we spend testing is at least equal to that we have spend developing, it is also a tool required in order to prove some measure of quality for the system.
Collectively all the tests have enabled us to attain a high internal quality within the code with use of good code practice methods like smoke tests, a test framework and extensive regression tests, while also having a high external quality to potential users of the API with a thoroughly tested API.


%1/3 test writing found a logical error.
%test makes u think also revealing errors
%Regression test the most helpful part
%Integration test didnt find JSON errors.(Testing doenst find all tests obviously) Manual sanity test(Smoke Test)
%System test finds bottlenecks // revealed, not acted upon - improvements ---

\subsection{Jenkins/CI}\fxnote{this needs writing}
\subsection{Splitting the System/Project Focus}
In \cref{cha:requirements_elicitation} we made the choice to focus on the server component.
While choosing to focus on the server, we still made a proof of concept version of the consumer client and emulated the producer client.
We did this in order to prove that the server we produced is compatible with arbitrary producer clients and consumer clients systems, as well as to testing scalability measures.

Having no stakeholder meant we had no one producing requirements for the server such as what services should be available through our server.
The consumer client development, while not strictly producing requirements, helped us figure out which services one might require and also worked as an integration test, finding numerous design faults that were subsequently rectified.
This was an unexpected advantage of having the the consumer client proof of concept development act like a user, that is a consumer client developer, as this is exactly whom our server is designed to interact with.
This interaction within the group has resulted in a more complete server with a wider range of services available to possible consumer client developers.

%Developer split, postive outcome
